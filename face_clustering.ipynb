{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hc3drAyLRYj"
      },
      "outputs": [],
      "source": [
        "!pip3 install face_recognition\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import face_recognition\n",
        "import os # reading file name\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN #clustering에 필요 \n",
        "import re #문자열에서 숫자 추출"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Face():\n",
        "  def __init__(self, frame_id, name, box, encoding):\n",
        "    self.frame_id = frame_id\n",
        "    self.name = name\n",
        "    self.box = box\n",
        "    self.encoding = encoding\n",
        "\n",
        "class Face_clustering():\n",
        "  def __init__(self):\n",
        "    self.faces = []\n",
        "    self.capture_dir = \"captures\"\n",
        "    self.unique_cnt_dict = {}\n",
        "    self.person_class = 0\n",
        "  def capture_filename(self, frame_id):\n",
        "    return \"frame_{}.jpg\".format(frame_id)\n",
        "  def drawBox(self, frame, face):\n",
        "   (top, right, bottom, left) = face.box\n",
        "   #print(face.frame_id)\n",
        "   cv2.rectangle(frame, (left,top), (right,bottom), (0,0,255), 2)\n",
        "\n",
        "  def encode(self, src_file='/content/drive/MyDrive/Colab_Notebooks/capstone1/tony_stark.mp4', capture_per_sec = 1, stop=0): #frame 하나에서 얼굴 추출\n",
        "    video = cv2.VideoCapture(src_file) \n",
        "    if not video.isOpened():\n",
        "      print(\"video not opened\")\n",
        "      return\n",
        "    \n",
        "    print(video.get(cv2.CAP_PROP_FRAME_COUNT)) #총 프레임 수 \n",
        "    print(video.get(cv2.CAP_PROP_FPS)) # 초당 프레임 수\n",
        "    print(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    print(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_per_sec = video.get(cv2.CAP_PROP_FPS)\n",
        "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "   # capture_per_sec = 1\n",
        "    frame_id=0\n",
        "    frame_between_capture = round(frame_per_sec / capture_per_sec) #30\n",
        "\n",
        "    if not os.path.exists(self.capture_dir): #/captures디렉토리가 없으면\n",
        "      os.mkdir(self.capture_dir)\n",
        "\n",
        "    while video.isOpened():\n",
        "      ret, frame = video.read()\n",
        "      frame_id+=1\n",
        "\n",
        "      if ret is True:\n",
        "        if frame_id % frame_between_capture == 0: \n",
        "          #cv2_imshow(frame)\n",
        "          \n",
        "          rgb_frame = frame[:,:,::-1] #BGR을 RGB 순으로 바꾸기\n",
        "          face_box = face_recognition.face_locations(rgb_frame, model=\"hog\")\n",
        "          face_encodings = face_recognition.face_encodings(rgb_frame, face_box)\n",
        "          # face_box.shape (top, right, bottom, left, face_개수)\n",
        "          #face_encodings.shape (128 vector, face_개수)\n",
        "          if not face_box:\n",
        "             # print(\"face_box 0: %d\" %frame_id)\n",
        "              continue\n",
        "\n",
        "          faces_in_frame = [] #feces_in_frame에 Face class 저장\n",
        "          for box, encodings in zip(face_box, face_encodings):\n",
        "            face = Face(frame_id, None, box, encodings)\n",
        "            faces_in_frame.append(face)\n",
        "            self.drawBox(frame, face)\n",
        "          \n",
        "\n",
        "          pathname = os.path.join(self.capture_dir, self.capture_filename(frame_id)) # captures/frame_#.jpg\n",
        "          cv2.imwrite(pathname, frame) # 해당 디렉토리에 이미지 저장\n",
        "\n",
        "          self.faces.extend(faces_in_frame) #extend는 iterable한것들을 append\n",
        "          #if cv2.waitKey(1) & 0xFF == ord('q'): # waitkey 안됨\n",
        "           # break\n",
        "      \n",
        "      else:\n",
        "        break\n",
        "    video.release()\n",
        "    return\n",
        "\n",
        "  def get_face_image(self, image, box):\n",
        "    (top, right, bottom, left) = box\n",
        "    image_height = image.shape[0]\n",
        "    image_width = image.shape[1]\n",
        "    box_width = right - left\n",
        "    box_height = bottom - top\n",
        "\n",
        "    top = max(top - box_height, 0)\n",
        "    bottom = min(bottom + box_height, image_height - 1)\n",
        "    left = max(left - box_width, 0)\n",
        "    right = min(right + box_width, image_width - 1)\n",
        "\n",
        "    return image[top:bottom, left:right]\n",
        "    #image (frame_height, frame_width, rgb)\n",
        "\n",
        "  def cluster(self):\n",
        "   # print(len(self.faces))\n",
        "    if len(self.faces) == 0:\n",
        "      return\n",
        "    encodings = [face.encoding for face in self.faces]\n",
        "\n",
        "    cm = DBSCAN(metric=\"euclidean\")\n",
        "    cm.fit(encodings)\n",
        "    # clustering 완료\n",
        "\n",
        "    label_ids, count = np.unique(cm.labels_, return_counts=True) #0부터 labeling, -1은 분류되지 않은 encoding\n",
        "    self.unique_cnt_dict = dict(zip(label_ids, count)) # 레이블당 프레임수\n",
        "    self.person_class = len(label_ids) - 1 #사람 종류\n",
        "    for label_id in label_ids:\n",
        "      dir_name = \"ID%d\" % label_id\n",
        "     # if label_id > -1: # -1처리는 어떻게 해야하나\n",
        "      if not os.path.exists(dir_name): #/id# 디렉토리가 없으면\n",
        "        os.mkdir(dir_name)\n",
        "      index = np.where(cm.labels_ == label_id)[0]\n",
        "      #print(index)\n",
        "    for i in index:\n",
        "      #  print(f'faces : {self.faces}')\n",
        "      #  print(f'i : {i}')\n",
        "      #  print(f'type i : {type(i)}')\n",
        "        \n",
        "        frame_id = self.faces[i].frame_id\n",
        "        box = self.faces[i].box\n",
        "        pathname = os.path.join(self.capture_dir, self.capture_filename(frame_id)) # captures/frame_#.jpg\n",
        "        image = cv2.imread(pathname)\n",
        "        face_image = self.get_face_image(image, box)\n",
        "        filename = dir_name + '-' + self.capture_filename(frame_id) #ID1/frame_#.jpg\n",
        "        pathname = os.path.join(dir_name, filename)\n",
        "        cv2.imwrite(pathname, face_image)\n",
        "\n",
        "    print('clustering done')\n",
        "\n",
        "  def image_to_video(self):\n",
        "    for i in range(self.person_class):\n",
        "      frame_id = []\n",
        "      dir_name = \"ID%d\" % i\n",
        "      for file in os.listdir(dir_name):\n",
        "        if '.jpg' in file:\n",
        "          id = int(file[:-4].split('_')[-1])\n",
        "          frame_id.append(id)\n",
        "      frame_id.sort()\n",
        "      for id in frame_id:\n",
        "        self.faces[id]\n"
      ],
      "metadata": {
        "id": "2jtie6IgLVcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  import argparse\n",
        "\n",
        "  #ap = argparse.ArgumentParser()\n",
        "  #ap.add_argument(\"-e\", \"--encode\", help=\"video file top encode or '0' to encode web cam\")\n",
        "  #ap.add_argument(\"-c\", \"--capture\", default=1, type=int, help=\"# of frame to capture per second\")\n",
        "  #ap.add_argument(\"-s\", \"--stop\", default=0, type=int, help=\"stop encoding after # seconds\")\n",
        "  #args = ap.parse_args()\n",
        "\n",
        "  fc = Face_clustering()\n",
        " # if args.encode:\n",
        " #   src_file = args.encode\n",
        " #   if src_file == \"0\":\n",
        " #     src_file = 0\n",
        " #   fc.encode(src_file, args.capture, args.stop)\n",
        "  fc.encode()\n",
        "  fc.cluster()"
      ],
      "metadata": {
        "id": "p9ftl2qNLZjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}